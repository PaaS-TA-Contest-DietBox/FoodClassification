{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, Conv2D, Flatten\n",
    "from tensorflow.keras.applications import MobileNetV2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Seed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = f'../Datasets/kfood/'\n",
    "CKPT_PATH = f'./checkpoints/baseline_learning_model.h5'\n",
    "LOG_PATH = './logs/baseline_model/' + datetime.now().strftime(\"%Y%n%d-%H%M%S\")\n",
    "\n",
    "size = 224\n",
    "batch_size = 64\n",
    "\n",
    "classes = 150\n",
    "\n",
    "learning_rate = 1e-2\n",
    "wd = 0.0005\n",
    "max_lr = 1e-2\n",
    "min_lr = 5e-5\n",
    "cycle_len = 20\n",
    "\n",
    "EPOCHS = 100\n",
    "use_pretrained = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 150513 images belonging to 150 classes.\n"
     ]
    }
   ],
   "source": [
    "# featurewise_center=True,\n",
    "# featurewise_std_normalization=True,\n",
    "# rotation_range=20,\n",
    "# width_shift_range=0.2,\n",
    "# height_shift_range=0.2,\n",
    "# horizontal_flip=True,\n",
    "# vertical_flip=True,\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255.,\n",
    "    dtype=np.float32\n",
    ")\n",
    "\n",
    "datagenerator = datagen.flow_from_directory(\n",
    "    DATA_PATH,\n",
    "    target_size=(size, size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = MobileNetV2(\n",
    "        input_shape=(size, size, 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "    )\n",
    "base_model.trainable = False\n",
    "\n",
    "def Baseline(base_model):\n",
    "    x = inputs = Input([size, size, 3])\n",
    "    x = base_model(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    output = Dense(classes, activation='softmax')(x)\n",
    "    return Model(inputs=inputs, outputs=output)\n",
    "\n",
    "with tf.device('/device:GPU:1'):\n",
    "    model = Baseline(base_model)\n",
    "    if use_pretrained:\n",
    "        model.load_weights(CKPT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "mobilenetv2_1.00_224 (Functi (None, 7, 7, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               655872    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 150)               76950     \n",
      "=================================================================\n",
      "Total params: 3,253,462\n",
      "Trainable params: 995,478\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tfa.optimizers.AdamW(learning_rate, wd)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=CKPT_PATH,\n",
    "    save_weights_only=False,\n",
    "    monitor='accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "def trainfle_fn(x):\n",
    "    return 1. / (2.**(x - 1))\n",
    "clr_f = tfa.optimizers.CyclicalLearningRate(\n",
    "    initial_learning_rate=(max_lr+min_lr)/2,\n",
    "    maximal_learning_rate=max_lr,\n",
    "    step_size=cycle_len,\n",
    "    scale_fn=trainfle_fn\n",
    ")\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(clr_f)\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='accuracy',\n",
    "    min_delta=0,\n",
    "    patience=30,\n",
    "    verbose=2,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=LOG_PATH,\n",
    "    histogram_freq=1\n",
    ")\n",
    "\n",
    "callbacks = [ckpt, lr_scheduler, early_stop, tensorboard]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   1/2352 [..............................] - ETA: 0s - loss: 3.3791 - accuracy: 0.1562WARNING:tensorflow:From /home/sungjin/anaconda3/envs/Pasta/lib/python3.7/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "  13/2352 [..............................] - ETA: 8:58 - loss: 3.5586 - accuracy: 0.1538"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sungjin/anaconda3/envs/Pasta/lib/python3.7/site-packages/PIL/Image.py:952: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  48/2352 [..............................] - ETA: 9:51 - loss: 3.4047 - accuracy: 0.1855"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sungjin/anaconda3/envs/Pasta/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:792: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 4. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 285/2352 [==>...........................] - ETA: 8:48 - loss: 3.3161 - accuracy: 0.1880"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sungjin/anaconda3/envs/Pasta/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:771: UserWarning: Possibly corrupt EXIF data.  Expecting to read 1498 bytes but only got 0. Skipping tag 37500\n",
      "  \"Possibly corrupt EXIF data.  \"\n",
      "/home/sungjin/anaconda3/envs/Pasta/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:771: UserWarning: Possibly corrupt EXIF data.  Expecting to read 125 bytes but only got 120. Skipping tag 37510\n",
      "  \"Possibly corrupt EXIF data.  \"\n",
      "/home/sungjin/anaconda3/envs/Pasta/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:771: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 41988\n",
      "  \"Possibly corrupt EXIF data.  \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 666/2352 [=======>......................] - ETA: 7:22 - loss: 3.2980 - accuracy: 0.1878"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sungjin/anaconda3/envs/Pasta/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:771: UserWarning: Possibly corrupt EXIF data.  Expecting to read 1078 bytes but only got 0. Skipping tag 37500\n",
      "  \"Possibly corrupt EXIF data.  \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1399/2352 [================>.............] - ETA: 4:15 - loss: 3.2981 - accuracy: 0.1878"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sungjin/anaconda3/envs/Pasta/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:771: UserWarning: Possibly corrupt EXIF data.  Expecting to read 20 bytes but only got 6. Skipping tag 272\n",
      "  \"Possibly corrupt EXIF data.  \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1547/2352 [==================>...........] - ETA: 3:35 - loss: 3.2966 - accuracy: 0.1881"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sungjin/anaconda3/envs/Pasta/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:771: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 2. Skipping tag 41486\n",
      "  \"Possibly corrupt EXIF data.  \"\n",
      "/home/sungjin/anaconda3/envs/Pasta/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:771: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 41487\n",
      "  \"Possibly corrupt EXIF data.  \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1634/2352 [===================>..........] - ETA: 3:12 - loss: 3.2974 - accuracy: 0.1880"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sungjin/anaconda3/envs/Pasta/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:771: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 2. Skipping tag 37386\n",
      "  \"Possibly corrupt EXIF data.  \"\n",
      "/home/sungjin/anaconda3/envs/Pasta/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:771: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 37396\n",
      "  \"Possibly corrupt EXIF data.  \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2352/2352 [==============================] - ETA: 0s - loss: 3.2996 - accuracy: 0.1867\n",
      "Epoch 00001: accuracy improved from -inf to 0.18667, saving model to ./checkpoints/baseline_learning_model.h5\n",
      "2352/2352 [==============================] - 629s 267ms/step - loss: 3.2996 - accuracy: 0.1867\n",
      "Epoch 2/100\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 3.3193 - accuracy: 0.1839\n",
      "Epoch 00002: accuracy did not improve from 0.18667\n",
      "2352/2352 [==============================] - 603s 256ms/step - loss: 3.3193 - accuracy: 0.1839\n",
      "Epoch 3/100\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 3.3229 - accuracy: 0.1800\n",
      "Epoch 00003: accuracy did not improve from 0.18667\n",
      "2352/2352 [==============================] - 599s 255ms/step - loss: 3.3229 - accuracy: 0.1800\n",
      "Epoch 4/100\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 3.3352 - accuracy: 0.1797\n",
      "Epoch 00004: accuracy did not improve from 0.18667\n",
      "2352/2352 [==============================] - 600s 255ms/step - loss: 3.3352 - accuracy: 0.1797\n",
      "Epoch 5/100\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 3.3469 - accuracy: 0.1782\n",
      "Epoch 00005: accuracy did not improve from 0.18667\n",
      "2352/2352 [==============================] - 600s 255ms/step - loss: 3.3469 - accuracy: 0.1782\n",
      "Epoch 6/100\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 3.3570 - accuracy: 0.1751\n",
      "Epoch 00006: accuracy did not improve from 0.18667\n",
      "2352/2352 [==============================] - 599s 255ms/step - loss: 3.3570 - accuracy: 0.1751\n",
      "Epoch 7/100\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 3.3765 - accuracy: 0.1729\n",
      "Epoch 00007: accuracy did not improve from 0.18667\n",
      "2352/2352 [==============================] - 598s 254ms/step - loss: 3.3765 - accuracy: 0.1729\n",
      "Epoch 8/100\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 3.3833 - accuracy: 0.1728\n",
      "Epoch 00008: accuracy did not improve from 0.18667\n",
      "2352/2352 [==============================] - 596s 253ms/step - loss: 3.3833 - accuracy: 0.1728\n",
      "Epoch 9/100\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 3.3946 - accuracy: 0.1698\n",
      "Epoch 00009: accuracy did not improve from 0.18667\n",
      "2352/2352 [==============================] - 596s 253ms/step - loss: 3.3946 - accuracy: 0.1698\n",
      "Epoch 10/100\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 3.4093 - accuracy: 0.1675\n",
      "Epoch 00010: accuracy did not improve from 0.18667\n",
      "2352/2352 [==============================] - 597s 254ms/step - loss: 3.4093 - accuracy: 0.1675\n",
      "Epoch 11/100\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 3.4334 - accuracy: 0.1628\n",
      "Epoch 00011: accuracy did not improve from 0.18667\n",
      "2352/2352 [==============================] - 598s 254ms/step - loss: 3.4334 - accuracy: 0.1628\n",
      "Epoch 12/100\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 3.4470 - accuracy: 0.1613\n",
      "Epoch 00012: accuracy did not improve from 0.18667\n",
      "2352/2352 [==============================] - 598s 254ms/step - loss: 3.4470 - accuracy: 0.1613\n",
      "Epoch 13/100\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 3.4689 - accuracy: 0.1573\n",
      "Epoch 00013: accuracy did not improve from 0.18667\n",
      "2352/2352 [==============================] - 598s 254ms/step - loss: 3.4689 - accuracy: 0.1573\n",
      "Epoch 14/100\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 3.4844 - accuracy: 0.1557\n",
      "Epoch 00014: accuracy did not improve from 0.18667\n",
      "2352/2352 [==============================] - 598s 254ms/step - loss: 3.4844 - accuracy: 0.1557\n",
      "Epoch 15/100\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 3.4968 - accuracy: 0.1536\n",
      "Epoch 00015: accuracy did not improve from 0.18667\n",
      "2352/2352 [==============================] - 598s 254ms/step - loss: 3.4968 - accuracy: 0.1536\n",
      "Epoch 16/100\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 3.5143 - accuracy: 0.1505\n",
      "Epoch 00016: accuracy did not improve from 0.18667\n",
      "2352/2352 [==============================] - 598s 254ms/step - loss: 3.5143 - accuracy: 0.1505\n",
      "Epoch 17/100\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 3.5299 - accuracy: 0.1477\n",
      "Epoch 00017: accuracy did not improve from 0.18667\n",
      "2352/2352 [==============================] - 597s 254ms/step - loss: 3.5299 - accuracy: 0.1477\n",
      "Epoch 18/100\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 3.5415 - accuracy: 0.1450\n",
      "Epoch 00018: accuracy did not improve from 0.18667\n",
      "2352/2352 [==============================] - 605s 257ms/step - loss: 3.5415 - accuracy: 0.1450\n",
      "Epoch 19/100\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 3.5410 - accuracy: 0.1466\n",
      "Epoch 00019: accuracy did not improve from 0.18667\n",
      "2352/2352 [==============================] - 604s 257ms/step - loss: 3.5410 - accuracy: 0.1466\n",
      "Epoch 20/100\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 3.5622 - accuracy: 0.1426\n",
      "Epoch 00020: accuracy did not improve from 0.18667\n",
      "2352/2352 [==============================] - 599s 255ms/step - loss: 3.5622 - accuracy: 0.1426\n",
      "Epoch 21/100\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 3.5858 - accuracy: 0.1386\n",
      "Epoch 00021: accuracy did not improve from 0.18667\n",
      "2352/2352 [==============================] - 599s 254ms/step - loss: 3.5858 - accuracy: 0.1386\n",
      "Epoch 22/100\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 3.5757 - accuracy: 0.1401\n",
      "Epoch 00022: accuracy did not improve from 0.18667\n",
      "2352/2352 [==============================] - 597s 254ms/step - loss: 3.5757 - accuracy: 0.1401\n",
      "Epoch 23/100\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 3.5622 - accuracy: 0.1429 ETA: 2s - loss: 3.5624 \n",
      "Epoch 00023: accuracy did not improve from 0.18667\n",
      "2352/2352 [==============================] - 597s 254ms/step - loss: 3.5622 - accuracy: 0.1429\n",
      "Epoch 24/100\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 3.5641 - accuracy: 0.1417\n",
      "Epoch 00024: accuracy did not improve from 0.18667\n",
      "2352/2352 [==============================] - 598s 254ms/step - loss: 3.5641 - accuracy: 0.1417\n",
      "Epoch 25/100\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 3.5470 - accuracy: 0.1429\n",
      "Epoch 00025: accuracy did not improve from 0.18667\n",
      "2352/2352 [==============================] - 603s 256ms/step - loss: 3.5470 - accuracy: 0.1429\n",
      "Epoch 26/100\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 3.5481 - accuracy: 0.1419\n",
      "Epoch 00026: accuracy did not improve from 0.18667\n",
      "2352/2352 [==============================] - 598s 254ms/step - loss: 3.5481 - accuracy: 0.1419\n",
      "Epoch 27/100\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 3.5515 - accuracy: 0.1425\n",
      "Epoch 00027: accuracy did not improve from 0.18667\n",
      "2352/2352 [==============================] - 600s 255ms/step - loss: 3.5515 - accuracy: 0.1425\n",
      "Epoch 28/100\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 3.5399 - accuracy: 0.1449\n",
      "Epoch 00028: accuracy did not improve from 0.18667\n",
      "2352/2352 [==============================] - 597s 254ms/step - loss: 3.5399 - accuracy: 0.1449\n",
      "Epoch 29/100\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 3.5370 - accuracy: 0.1442\n",
      "Epoch 00029: accuracy did not improve from 0.18667\n",
      "2352/2352 [==============================] - 599s 255ms/step - loss: 3.5370 - accuracy: 0.1442\n",
      "Epoch 30/100\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 3.5321 - accuracy: 0.1446\n",
      "Epoch 00030: accuracy did not improve from 0.18667\n",
      "2352/2352 [==============================] - 600s 255ms/step - loss: 3.5321 - accuracy: 0.1446\n",
      "Epoch 31/100\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 3.5220 - accuracy: 0.1463\n",
      "Epoch 00031: accuracy did not improve from 0.18667\n",
      "Restoring model weights from the end of the best epoch.\n",
      "2352/2352 [==============================] - 600s 255ms/step - loss: 3.5220 - accuracy: 0.1463\n",
      "Epoch 00031: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    datagenerator,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pasta",
   "language": "python",
   "name": "pasta"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
